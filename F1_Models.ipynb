{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "# SK Packages\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "file = 'C:/Users/Alex/OneDrive/BrainStation/Data_Science_Bootcamp/Capstone_Project/capstone-Aboard89/model_data.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_index</th>\n",
       "      <th>year</th>\n",
       "      <th>F2_champion</th>\n",
       "      <th>Former_F1_World_Champion</th>\n",
       "      <th>home_race</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>starting_grid_position</th>\n",
       "      <th>points_in_previous_race</th>\n",
       "      <th>laps_in_previous_race</th>\n",
       "      <th>race_win</th>\n",
       "      <th>...</th>\n",
       "      <th>Nationality_Monegasque</th>\n",
       "      <th>Nationality_New Zealander</th>\n",
       "      <th>Nationality_Polish</th>\n",
       "      <th>Nationality_Portuguese</th>\n",
       "      <th>Nationality_Russian</th>\n",
       "      <th>Nationality_Spanish</th>\n",
       "      <th>Nationality_Swedish</th>\n",
       "      <th>Nationality_Swiss</th>\n",
       "      <th>Nationality_Thai</th>\n",
       "      <th>Nationality_Venezuelan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_index  year  F2_champion  Former_F1_World_Champion  home_race  \\\n",
       "0           2  1995            0                         0          0   \n",
       "1           2  1995            0                         0          0   \n",
       "2           2  1995            0                         0          0   \n",
       "3           2  1995            0                         1          0   \n",
       "4           2  1995            0                         0          0   \n",
       "\n",
       "   constructorId  starting_grid_position  points_in_previous_race  \\\n",
       "0              1                      17                      1.0   \n",
       "1              1                       5                      3.0   \n",
       "2              3                       1                      6.0   \n",
       "3              3                       2                      0.0   \n",
       "4              6                       6                      2.0   \n",
       "\n",
       "   laps_in_previous_race  race_win  ...  Nationality_Monegasque  \\\n",
       "0                   70.0         0  ...                   False   \n",
       "1                   70.0         0  ...                   False   \n",
       "2                   71.0         0  ...                   False   \n",
       "3                   30.0         1  ...                   False   \n",
       "4                   70.0         0  ...                   False   \n",
       "\n",
       "   Nationality_New Zealander  Nationality_Polish  Nationality_Portuguese  \\\n",
       "0                      False               False                   False   \n",
       "1                      False               False                   False   \n",
       "2                      False               False                   False   \n",
       "3                      False               False                   False   \n",
       "4                      False               False                   False   \n",
       "\n",
       "   Nationality_Russian  Nationality_Spanish  Nationality_Swedish  \\\n",
       "0                False                False                False   \n",
       "1                False                False                False   \n",
       "2                False                False                False   \n",
       "3                False                False                False   \n",
       "4                False                False                False   \n",
       "\n",
       "   Nationality_Swiss  Nationality_Thai  Nationality_Venezuelan  \n",
       "0              False             False                   False  \n",
       "1              False             False                   False  \n",
       "2              False             False                   False  \n",
       "3              False             False                   False  \n",
       "4              False             False                   False  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test-Split the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)  # You can adjust the test_size as needed\n",
    "\n",
    "# Save training and testing data to separate CSV files\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the normalized value counts for the 'race_win' column and multiply by 100 to get percentages\n",
    "value_counts = train_data['race_win'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure()\n",
    "plt.bar(value_counts.index.astype(str), value_counts.values)\n",
    "plt.xlabel('Race Win or Not')\n",
    "plt.ylabel('Percentage of Total Training Set (%)')\n",
    "plt.xticks([0, 1], ['Did not Win', 'Did Win'])\n",
    "plt.title('Distribution of \"Win\" rows in dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar chart displays the class distribution for the training dataset concerning Formula 1 race outcomes, specifically showing the proportion of instances where a driver did not win compared to when they did. The stark contrast suggests a significant class imbalance, with the \"Did not Win\" category heavily outweighing the \"Did Win\" one. In predictive modeling, this imbalance poses a challenge because models might become biased towards predicting the majority class, in this case, \"Did not Win.\" As a result, the model might perform poorly in correctly predicting the less frequent, but often more interesting, \"Did Win\" instances. To address this, techniques such as resampling, or specialized ML algorithms that are robust to class imbalance might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Logistics Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y for the training model\n",
    "X_train = train_data.drop('race_win', axis=1)\n",
    "y_train = train_data['race_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training data (to see how well the model does on the data it was trained on)\n",
    "y_train_pred = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8254   65]\n",
      " [ 321   96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      8319\n",
      "           1       0.60      0.23      0.33       417\n",
      "\n",
      "    accuracy                           0.96      8736\n",
      "   macro avg       0.78      0.61      0.65      8736\n",
      "weighted avg       0.95      0.96      0.95      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix and the classification report provide an overview of the model's performance on the training set for predicting F1 race winners. From the confusion matrix, we see that the model predicted 'Did not Win' (class 0) correctly 8254 times, but it incorrectly predicted 'Did Win' (class 1) as 'Did not Win' 321 times. For the actual wins, the model only correctly predicted 961 instances of 'Did Win' and incorrectly predicted 'Did not Win' 65 times. \n",
    "\n",
    "The classification report provides further insight. While the model is quite precise at identifying the 'Did not Win' cases (96% precision), its recall for the 'Did Win' cases is only 23%, indicating it misses many actual wins. Consequently, the f1-score for the 'Did Win' predictions is low at 0.33, due to the poor recall. This seems to link in with the earlier identified class imbalance and indicates that while the model is adept at identifying non-winners, it struggles to identify the actual winners, which are of more interest in this context.\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "1. I will experiment with different algorithms that are more robust to imbalanced datasets, such as ensemble methods. Fine-tuning the model's hyperparameters could also enhance predictive performance.\n",
    "\n",
    "2. Additionally, to improve the model's ability to predict F1 race winners, I will consider addressing the class imbalance by employing techniques such as oversampling the minority class (I can't really undersample the majority class as there are too few minority class). \n",
    "\n",
    "3. Another option is incorporating more discriminative features or engineered features that capture the dynamics of race-winning factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Optimizing LogReg Using Pipeline and Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a directory to cache the pipeline results\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "# Set up a pipeline\n",
    "# The steps here act as placeholders and will be changed when we pass the pipeline\n",
    "\n",
    "my_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "('dim_reducer', PCA()),\n",
    "('model', LogisticRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Let's try the same range of C values from earlier\n",
    "c_values = [.00001, .0001, .001, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Parameter grid\n",
    "logreg_param_grid = [\n",
    "    # L1 without PCA\n",
    "    {'scaler': [None, StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "     'dim_reducer': [None],\n",
    "     'model': [LogisticRegression(penalty='l1', solver='saga', random_state=1, n_jobs=-1, max_iter=100)],\n",
    "     'model__C': c_values},\n",
    "\n",
    "    # L1 with PCA\n",
    "    {'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components': [0.95, 0.9, 0.85, 0.8],\n",
    "     'model': [LogisticRegression(penalty='l1', solver='saga', random_state=1, n_jobs=-1, max_iter=100)],\n",
    "     'model__C': c_values},\n",
    "\n",
    "    # L2 (default) without PCA\n",
    "    {'scaler': [None, StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "     'dim_reducer': [None],\n",
    "     'model': [LogisticRegression(penalty='l2', solver='lbfgs', random_state=1, n_jobs=-1, max_iter=100)],\n",
    "     'model__C': c_values},\n",
    "\n",
    "    # L2 (default) with PCA\n",
    "    {'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "     'dim_reducer': [PCA()],\n",
    "     'dim_reducer__n_components': [0.95, 0.9, 0.85, 0.8],\n",
    "     'model': [LogisticRegression(penalty='l2', solver='lbfgs', random_state=1, n_jobs=-1, max_iter=100)],\n",
    "     'model__C': c_values}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m logreg_gs \u001b[38;5;241m=\u001b[39m GridSearchCV(my_pipeline, param_grid\u001b[38;5;241m=\u001b[39mlogreg_param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the log reg grid search\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m fitted_logreg_gs \u001b[38;5;241m=\u001b[39m \u001b[43mlogreg_gs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the log reg grid search\n",
    "logreg_gs = GridSearchCV(my_pipeline, param_grid=logreg_param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the log reg grid search\n",
    "fitted_logreg_gs = logreg_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'dim_reducer': None, 'model': LogisticRegression(C=10000, n_jobs=-1, random_state=1), 'model__C': 10000, 'scaler': StandardScaler()}\n",
      "Best score: 0.9558146099426411\n"
     ]
    }
   ],
   "source": [
    "# Reviewing the results\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(logreg_gs.best_params_)\n",
    "print(\"Best score:\", logreg_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y for the training model\n",
    "X_test = test_data.drop('race_win', axis=1)\n",
    "y_test = test_data['race_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set features using the pipeline's transform method\n",
    "X_test_scaled = logreg_gs.best_estimator_.named_steps['scaler'].transform(X_test)\n",
    "\n",
    "# make predictions with the scaled test features using the best estimator\n",
    "y_pred = logreg_gs.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the best estimator\n",
    "y_pred = logreg_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2057   20]\n",
      " [  73   35]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2077\n",
      "           1       0.64      0.32      0.43       108\n",
      "\n",
      "    accuracy                           0.96      2185\n",
      "   macro avg       0.80      0.66      0.70      2185\n",
      "weighted avg       0.95      0.96      0.95      2185\n",
      "\n",
      "Accuracy: 0.9574370709382151\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the new confusion matrix, we can see that the model predicted the majority class (0, presumably the 'non-winner') quite accurately, with 2057 true negatives and only 20 false positives. However, it struggled more with the minority class (1, presumably the 'winner'), with a higher proportion of false negatives (73) relative to true positives (35). \n",
    "\n",
    "The classification report provides additional insight. The precision for class 1 is 0.64, meaning that when the model predicts a race winner, it is correct 64% of the time. The recall for class 1 is 0.32, indicating that the model only identifies 32% of the actual race winners. This is reflected in the lower F1-score for class 1 (0.43), which is a harmonic mean of precision and recall, showing that the model is less adept at predicting winners than non-winners.\n",
    "\n",
    "Overall, the model is quite accurate (95.47%) when considering both classes together, but this high accuracy is largely due to its performance on the majority class. The relatively low F1-score for predicting winners suggests that there is room for improvement, particularly in how the model identifies the comparatively rare event of a race win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comparison of the models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two models for our F1 race winner prediction project, the two models have similar accuracy scores, but the second \"tuned\" model is more effective at predicting the positive class (label 1), which is our class of interest (the actual race winners). The second \"tuned\" model had a better balance between sensitivity and precision for the positive class, with a recall of 0.32 versus 0.23 in the first model, suggesting it was better at identifying actual winners, despite a slightly lower overall accuracy. This trade-off is important in our project context where the correct prediction of race winners (a likely rare event) is more valuable than the overall accuracy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. **GridSearch with Decision Tree for comparison vs LogReg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multiple pipeline objects for multiple models\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('LR', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()),\n",
    "                    ('DT',DecisionTreeClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seperate parameter grid for each model\n",
    "lr_param_grid = [{'LR__penalty': ['l1', 'l2'],\n",
    "                   'LR__C': [1.0, 0.5, 0.1],\n",
    "                   'LR__solver': ['liblinear']}]\n",
    "dt_param_grid = [{'DT__criterion': ['gini', 'entropy'],\n",
    "                   'DT__min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
    "                   'DT__max_depth': [1, 2, 3, 4, 5, 6],\n",
    "                   'DT__min_samples_split': [2, 3, 4, 5, 6]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, create a gridsearchcv object with the param grid\n",
    "lr_grid_search = GridSearchCV(estimator=pipe_lr,\n",
    "        param_grid=lr_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=5)\n",
    "dt_grid_search = GridSearchCV(estimator=pipe_dt,\n",
    "        param_grid=dt_param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together\n",
    "grids = [lr_grid_search, dt_grid_search]\n",
    "for pipe in grids:\n",
    "    pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9560640732265446\n",
      "Logistic Regression Best Params: {'LR__C': 1.0, 'LR__penalty': 'l1', 'LR__solver': 'liblinear'}\n",
      "Decision Trees Test Accuracy: 0.9446224256292907\n",
      "Decision Trees Best Params: {'DT__criterion': 'gini', 'DT__max_depth': 3, 'DT__min_samples_leaf': 4, 'DT__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# find out performance of each model and best params\n",
    "grid_dict = {0: 'Logistic Regression', 1: 'Decision Trees'}\n",
    "for i, model in enumerate(grids):\n",
    "    print('{} Test Accuracy: {}'.format(grid_dict[i],model.score(X_test,y_test)))\n",
    "    print('{} Best Params: {}'.format(grid_dict[i],model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Analyse the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions from the best logistic regression model\n",
    "y_pred_lr = logreg_gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions from the best decision tree model\n",
    "y_pred_dt = dt_grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2077\n",
      "           1       0.64      0.32      0.43       108\n",
      "\n",
      "    accuracy                           0.96      2185\n",
      "   macro avg       0.80      0.66      0.70      2185\n",
      "weighted avg       0.95      0.96      0.95      2185\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2077\n",
      "           1       0.42      0.33      0.37       108\n",
      "\n",
      "    accuracy                           0.94      2185\n",
      "   macro avg       0.69      0.65      0.67      2185\n",
      "weighted avg       0.94      0.94      0.94      2185\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[2057   20]\n",
      " [  73   35]]\n",
      "Decision Tree Confusion Matrix:\n",
      "[[2028   49]\n",
      " [  72   36]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification reports and confusion matrices for our F1 race winner prediction project reveal key insights into model performance. The Logistic Regression model has high precision and recall for the majority class (label 0), but it struggles with the minority class (label 1 - the actual race winners), with significantly lower recall. This means it often misses identifying the true race winners. \n",
    "\n",
    "The Decision Tree model shows a slightly more balanced performance between the classes, though overall it has lower precision and recall, which might lead to more false positives and false negatives overall. \n",
    "\n",
    "The confusion matrices further highlight these points: Logistic Regression correctly identifies non-winners most of the time but fails to identify winners reliably, while the Decision Tree sacrifices some accuracy on the majority class for a tiny improvement in identifying winners.\n",
    "\n",
    "Either way, the results still aren't great at predicting the race winner, so we will need to work on other ideas to improve our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2077\n",
      "           1       0.53      0.26      0.35       108\n",
      "\n",
      "    accuracy                           0.95      2185\n",
      "   macro avg       0.75      0.62      0.66      2185\n",
      "weighted avg       0.94      0.95      0.94      2185\n",
      "\n",
      "[[2052   25]\n",
      " [  80   28]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "y_pred_rf = classifier.predict(X_test)\n",
    "\n",
    "# Print the classification report and confusion matrix for Non-Tuned Random Forest\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try and tune the model, to see if we can come up with any better models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters found: {'max_depth': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "# Initialize the grid search model\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the grid search determined that the highest number of n_estimators (300) in our parameter grid yielded the best results, I am curious to see if increasing n_estimators even further would lead to improvements in our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters found: {'max_depth': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "# Initialize the grid search model\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95938215 0.95535203 0.95248998 0.95134516 0.95420721]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model.sav']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(classifier, 'finalized_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = joblib.load('finalized_model.sav')\n",
    "\n",
    "# Predict new data\n",
    "new_data_predictions = loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9519450800915332\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, new_data_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2052   25]\n",
      " [  80   28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2077\n",
      "           1       0.53      0.26      0.35       108\n",
      "\n",
      "    accuracy                           0.95      2185\n",
      "   macro avg       0.75      0.62      0.66      2185\n",
      "weighted avg       0.94      0.95      0.94      2185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report for Tuned Random Forest\n",
    "print(confusion_matrix(y_test, new_data_predictions))\n",
    "print(classification_report(y_test, new_data_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our quest to predict Formula 1 race winners, we've employed a Random Forest algorithm, examining its performance in both non-tuned and tuned states. For the non-tuned Random Forest model, the classification report reveals a high precision and recall for class 0 (non-winners), suggesting strong performance in identifying races where a driver did not win. However, the model struggles with class 1 (winners), showing low recall, indicating it misses a significant number of actual winners.\n",
    "\n",
    "The confusion matrix for the non-tuned model, with values [[2052, 25], [80, 28]], further illustrates this point: out of 108 actual winners, it correctly identifies only 28, missing 80 — a substantial portion.\n",
    "\n",
    "Shifting our focus to the tuned Random Forest, which has been optimized with a maximum depth of 10 and 300 estimators, we observe no change. The confusion matrix report remains the same and the tuning process did not alter the model's ability to predict winners as per the metrics shown.\n",
    "\n",
    "In conclusion, while tuning parameters has optimized our model, it has not effectively enhanced its predictive accuracy for race winners (class 1). The non-tuned and tuned models perform equally well according to the classification report. Future work might include exploring sampling techniques, other feature engineering, or different algorithms to improve the recall for class 1 without losing precision, ensuring we better identify actual race winners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Correcting the Imbalance in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the high-stakes world of Formula 1 racing, predicting race winners is a unique binary classification challenge marked by a significant class imbalance, as shown earlier on in this notebook. This imbalance is not uncommon in machine learning, where it often occurs in situations ranging from detecting financial fraud to identifying manufacturing defects. \n",
    "\n",
    "To tackle this, we can employ techniques like the **Synthetic Minority Oversampling Technique (SMOTE)**, which synthetically boosts the presence of the minority class—in our case, actual race winners—within the dataset. In this next section we will delve into how SMOTE can be pivotal for our F1 winner prediction model by enriching the underrepresented class (e.g. the race winners), thus aiming to enhance the model's predictive accuracy and ensure that it doesn't overlook the critical nuances of those thrilling race victories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "smote_df = pd.read_csv('C:/Users/Alex/OneDrive/BrainStation/Data_Science_Bootcamp/Capstone_Project/capstone-Aboard89/model_data.csv')\n",
    "\n",
    "# Separate into features and target variable\n",
    "X = smote_df.drop('race_win', axis=1)\n",
    "y = smote_df['race_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create a SMOTE object\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Fit SMOTE to the training data\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:546: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "c:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:558: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "brf.fit(X_train, y_train)\n",
    "y_pred = brf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_fit_context' from 'sklearn.base' (c:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m rfc \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m rfc\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\ensemble\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.ensemble` module includes ensemble-based methods for\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mclassification, regression and anomaly detection.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bagging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaggingClassifier, BaggingRegressor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEnsemble\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     ExtraTreesClassifier,\n\u001b[0;32m      9\u001b[0m     ExtraTreesRegressor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     RandomTreesEmbedding,\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierMixin, RegressorMixin, _fit_context\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, r2_score\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier, DecisionTreeRegressor\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_fit_context' from 'sklearn.base' (c:\\Users\\Alex\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\base.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
